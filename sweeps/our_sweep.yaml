program: src/OUR.py
method: grid  # Options: grid, random, bayes (random recommended for large search spaces)
run_cap: 1  # Maximum number of runs for this sweep (optional, remove for unlimited)
metric:
  name: val_loss  # Use validation loss to guide sweep (minimize to avoid overfitting)
  goal: minimize
  # Alternative: use train_loss if no validation set is provided
  # name: train_loss
  # goal: minimize

parameters:
  input:
    value: train_2m.csv  # Update with your actual training file path
  
  k:
    values: [4]
  
  dim:
    values: [256]
  
  lr:
    values: [0.0001]  
  
  epoch:
    values: [10]
  
  batch_size:
    values: [32]  # 0 means full dataset
  
  max_views_per_read:
    values: [4]
  
  max_read_num:
    values: [100]  # 0 means all
  
  temperature:
    values: [0.05]
  
  seed:
    value: 26042024
  
  device:
    value: cuda
  
  workers_num:
    value: 1
  
  checkpoint:
    value: 0
  
  output:
    value: models/our_model.pt  # Will be saved with epoch and LR in filename by the script
  
  wandb_project:
    value: dna-embedding-our
  
  wandb_mode:
    value: online
  
  val_input:
    value: val_48k.csv  # Validation file for computing validation loss (used for early stopping and sweep optimization)
  
  # Evaluation disabled during sweep - use separate evaluation script
  # eval_data_dir:
  #   value: null

